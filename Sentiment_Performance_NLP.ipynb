{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module uses Annual Report of 'Costco' that is a publicly listed company and analyses the management's discussion section. This section of the report if written with a negative sentiment shows the performance is going down. The dictionary used is Loughran-McDonald words dictionary because the standard NLTK dictionary does not hold true in case of finance due to different contextual meaning.\n",
    "\n",
    "The process is as follows:\n",
    "1. Read the MD&A from an annual report and tokenize the same\n",
    "2. Remove stop words such as and, of, the, etc.\n",
    "3. Importing Loughran-McDonald dictionaries and separating the words into positive and negative words\n",
    "4. Calculating overall sentiment score\n",
    "\n",
    "The analysis can be easily reproduced for other firms to check their sentiment using this approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in the Costco 2017 report are 6177\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Costco in 2017\n",
    "'''\n",
    "\n",
    "with open (\"costco_2017.txt\") as f:\n",
    "    tokens_old = nltk.word_tokenize(f.read())\n",
    "    \n",
    "no_digit = re.compile('.*[A-Za-z].*')\n",
    "tokens = [w for w in tokens_old if no_digit.match(w)]\n",
    "tokens = list(map(lambda x: x.lower(),tokens))\n",
    "print(\"Total words in the Costco 2017 report are {0}\".format(len(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop words are ['and', 'of', 'the', 'in', 'to', 'our', 'sales', 'a', 'we', 'net']\n"
     ]
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(tokens)\n",
    "stop = []\n",
    "for word, frequency in fdist.most_common(10):\n",
    "    stop.append(word)\n",
    "print(\"Stop words are {0}\".format(stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1599\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for word in tokens:\n",
    "    if word in stop:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The stopwords do not have 'no', 'not' and 'never' in them\n",
    "So, directly removing these words in the next step\n",
    "'''\n",
    "final_tokens = [x for x in tokens if x not in stop]\n",
    "total_tokens = len(final_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total positive words are 63\n",
      "Positive words are: \n",
      "['profitability', 'achieved', 'exclusive', 'enhancing', 'profitability', 'successful', 'despite', 'benefit', 'achieve', 'desirable', 'profitability', 'profitability', 'achieve', 'profitability', 'achieved', 'successes', 'achieving', 'enhancing', 'satisfaction', 'better', 'benefit', 'benefit', 'positively', 'benefit', 'benefit', 'positively', 'positive', 'positively', 'positively', 'effective', 'reward', 'positive', 'positively', 'positively', 'benefit', 'improvement', 'benefit', 'benefit', 'benefit', 'positively', 'benefit', 'positively', 'positively', 'positive', 'benefit', 'improvement', 'benefit', 'benefit', 'gains', 'gains', 'outstanding', 'effective', 'favorably', 'positively', 'outstanding', 'outstanding', 'outstanding', 'reward', 'reward', 'reward', 'progress', 'effective', 'gains']\n",
      "\n",
      "Total negative words are 46\n",
      "Negative words are: \n",
      "['question', 'negatively', 'negatively', 'decline', 'difficult', 'negative', 'negatively', 'negative', 'negative', 'losing', 'negatively', 'negative', 'negatively', 'negatively', 'negative', 'losing', 'negatively', 'negatively', 'negatively', 'negative', 'negatively', 'losses', 'losses', 'negatively', 'adverse', 'adverse', 'adverse', 'adverse', 'cancellation', 'penalty', 'critical', 'impairment', 'shrinkage', 'impairment', 'impairment', 'closing', 'impairment', 'downward', 'catastrophic', 'damage', 'loss', 'claims', 'severity', 'claims', 'challenge', 'adverse']\n"
     ]
    }
   ],
   "source": [
    "# Source: https://sraf.nd.edu/textual-analysis/resources/\n",
    "# This source provides Loughran-McDonald Sentiment word lists for finance\n",
    "lm_neg = open(\"LM_neg_words.txt\").read().lower()\n",
    "lm_pos = open(\"LM_pos_words.txt\").read().lower()\n",
    "\n",
    "li_neg = lm_neg.split('\\n')\n",
    "li_pos = lm_pos.split('\\n')\n",
    "\n",
    "checking = {}\n",
    "checking['positive'] = li_pos\n",
    "checking['negative'] = li_neg\n",
    "\n",
    "result_pos = []\n",
    "result_neg = []\n",
    "for word in final_tokens:\n",
    "    if word in checking['positive']:\n",
    "        result_pos.append(word)\n",
    "    elif word in checking['negative']:\n",
    "        result_neg.append(word)\n",
    "\n",
    "print()\n",
    "print(\"Total positive words are {0}\".format(len(result_pos)))\n",
    "print('Positive words are: ')\n",
    "print(result_pos)\n",
    "print()\n",
    "print(\"Total negative words are {0}\".format(len(result_neg)))\n",
    "print('Negative words are: ')\n",
    "print(result_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Costco's total sentiment in 2017 is : 0.003713411970292704\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Calculating\n",
    "(positive words - negative words)/total words\n",
    "'''\n",
    "\n",
    "pos = len(result_pos)\n",
    "neg = len(result_neg)\n",
    "\n",
    "sentiment = (pos-neg)/total_tokens\n",
    "print()\n",
    "print(\"Costco's total sentiment in 2017 is : {0}\".format(sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in the Costco 2016 report are 6129\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Costco 2016\n",
    "'''\n",
    "\n",
    "with open (\"costco_2016.txt\") as f2:\n",
    "    tokens_old = nltk.word_tokenize(f2.read())\n",
    "    \n",
    "no_digit2 = re.compile('.*[A-Za-z].*')\n",
    "tokens2 = [w for w in tokens_old if no_digit2.match(w)]\n",
    "tokens2 = list(map(lambda x: x.lower(),tokens2))\n",
    "print(\"Total words in the Costco 2016 report are {0}\".format(len(tokens2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop words are ['and', 'of', 'the', 'in', 'to', 'our', 'sales', 'a', 'we', 'net']\n"
     ]
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(tokens2)\n",
    "stop2 = []\n",
    "for word, frequency in fdist.most_common(10):\n",
    "    stop2.append(word)\n",
    "print(\"Stop words are {0}\".format(stop2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1602\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for word in tokens2:\n",
    "    if word in stop2:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The stopwords do not have 'no', 'not' and 'never' in them\n",
    "So, directly removing these words in the next step\n",
    "'''\n",
    "final_tokens2 = [x for x in tokens2 if x not in stop2]\n",
    "total_tokens2 = len(final_tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total positive words are 61\n",
      "Positive words are: \n",
      "['profitability', 'achieved', 'exclusive', 'enhancing', 'profitability', 'successful', 'despite', 'benefit', 'achieve', 'desirable', 'profitability', 'profitability', 'achieve', 'profitability', 'achieved', 'successes', 'achieving', 'enhancing', 'satisfaction', 'better', 'benefit', 'positively', 'benefit', 'outstanding', 'exclusive', 'positively', 'positively', 'benefit', 'positively', 'benefit', 'positively', 'positively', 'positive', 'benefit', 'improvement', 'benefit', 'positively', 'benefit', 'benefit', 'benefit', 'improvement', 'improvements', 'improvement', 'outstanding', 'gains', 'gains', 'favorable', 'gains', 'effective', 'favorably', 'benefit', 'positively', 'outstanding', 'outstanding', 'outstanding', 'reward', 'reward', 'reward', 'progress', 'effective', 'gains']\n",
      "\n",
      "Total negative words are 52\n",
      "Negative words are: \n",
      "['question', 'negatively', 'negatively', 'decline', 'difficult', 'negative', 'negatively', 'negative', 'adversely', 'negatively', 'negative', 'negatively', 'negatively', 'negative', 'losing', 'negatively', 'negative', 'negatively', 'negatively', 'negative', 'negatively', 'negatively', 'negatively', 'negative', 'negatively', 'negative', 'negatively', 'negatively', 'negative', 'negatively', 'negatively', 'adverse', 'adverse', 'adverse', 'cancellation', 'penalty', 'critical', 'impairment', 'losses', 'impairment', 'impairment', 'closing', 'impairment', 'downward', 'damage', 'claims', 'severity', 'claims', 'challenge', 'adverse', 'losses', 'volatility']\n"
     ]
    }
   ],
   "source": [
    "lm_neg2 = open(\"LM_neg_words.txt\").read().lower()\n",
    "lm_pos2 = open(\"LM_pos_words.txt\").read().lower()\n",
    "\n",
    "li_neg2 = lm_neg2.split('\\n')\n",
    "li_pos2 = lm_pos2.split('\\n')\n",
    "\n",
    "checking2 = {}\n",
    "checking2['positive'] = li_pos2\n",
    "checking2['negative'] = li_neg2\n",
    "\n",
    "result_pos2 = []\n",
    "result_neg2 = []\n",
    "for word in final_tokens2:\n",
    "    if word in checking2['positive']:\n",
    "        result_pos2.append(word)\n",
    "    elif word in checking2['negative']:\n",
    "        result_neg2.append(word)\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Total positive words are {0}\".format(len(result_pos2)))\n",
    "print('Positive words are: ')\n",
    "print(result_pos2)\n",
    "print()\n",
    "print(\"Total negative words are {0}\".format(len(result_neg2)))\n",
    "print('Negative words are: ')\n",
    "print(result_neg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Costco's total sentiment in 2016 was : 0.0019880715705765406\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Calculating\n",
    "(positive words - negative words)/total words\n",
    "'''\n",
    "\n",
    "pos2 = len(result_pos2)\n",
    "neg2 = len(result_neg2)\n",
    "\n",
    "sentiment2 = (pos2-neg2)/total_tokens2\n",
    "print()\n",
    "print(\"Costco's total sentiment in 2016 was : {0}\".format(sentiment2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in the Costco 2015 report are 5761\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Costco 2015\n",
    "'''\n",
    "with open (\"costco_2015.txt\") as f3:\n",
    "    tokens_old = nltk.word_tokenize(f3.read())\n",
    "    \n",
    "no_digit3 = re.compile('.*[A-Za-z].*')\n",
    "tokens3 = [w for w in tokens_old if no_digit3.match(w)]\n",
    "tokens3 = list(map(lambda x: x.lower(),tokens3))\n",
    "print(\"Total words in the Costco 2015 report are {0}\".format(len(tokens3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop words are ['and', 'of', 'the', 'in', 'to', 'our', 'a', 'sales', 'we', 'by']\n"
     ]
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(tokens3)\n",
    "stop3 = []\n",
    "for word, frequency in fdist.most_common(10):\n",
    "    stop3.append(word)\n",
    "print(\"Stop words are {0}\".format(stop3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1523\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for word in tokens3:\n",
    "    if word in stop3:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The stopwords do not have 'no', 'not' and 'never' in them\n",
    "So, directly removing these words in the next step\n",
    "'''\n",
    "final_tokens3 = [x for x in tokens3 if x not in stop3]\n",
    "total_tokens3 = len(final_tokens3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total positive words are 57\n",
      "Positive words are: \n",
      "['profitability', 'achieved', 'exclusive', 'enhancing', 'profitability', 'successful', 'despite', 'benefit', 'achieve', 'desirable', 'profitability', 'profitability', 'achieve', 'profitability', 'achieved', 'successes', 'achieving', 'enhancing', 'satisfaction', 'better', 'benefit', 'positively', 'benefit', 'positively', 'positively', 'improvement', 'benefit', 'positively', 'benefit', 'benefit', 'positive', 'improvement', 'benefit', 'improvement', 'improvements', 'improvement', 'despite', 'improvements', 'benefit', 'gains', 'gains', 'favorable', 'gains', 'gains', 'effective', 'favorably', 'benefit', 'stronger', 'outstanding', 'outstanding', 'outstanding', 'reward', 'reward', 'reward', 'progress', 'effective', 'gains']\n",
      "\n",
      "Total negative words are 48\n",
      "Negative words are: \n",
      "['question', 'negatively', 'negatively', 'decline', 'difficult', 'negative', 'negatively', 'negative', 'adversely', 'negatively', 'negative', 'negatively', 'negatively', 'negative', 'losing', 'negatively', 'negative', 'negatively', 'negatively', 'negative', 'losing', 'negatively', 'negatively', 'negative', 'negatively', 'negatively', 'negative', 'negatively', 'negatively', 'revoked', 'cancellation', 'penalty', 'critical', 'impairment', 'losses', 'impairment', 'impairment', 'closing', 'impairment', 'downward', 'damage', 'claims', 'severity', 'claims', 'challenge', 'losses', 'volatility', 'exposes']\n"
     ]
    }
   ],
   "source": [
    "lm_neg3 = open(\"LM_neg_words.txt\").read().lower()\n",
    "lm_pos3 = open(\"LM_pos_words.txt\").read().lower()\n",
    "\n",
    "li_neg3 = lm_neg3.split('\\n')\n",
    "li_pos3 = lm_pos3.split('\\n')\n",
    "\n",
    "checking3 = {}\n",
    "checking3['positive'] = li_pos3\n",
    "checking3['negative'] = li_neg3\n",
    "\n",
    "result_pos3 = []\n",
    "result_neg3 = []\n",
    "for word in final_tokens3:\n",
    "    if word in checking3['positive']:\n",
    "        result_pos3.append(word)\n",
    "    elif word in checking3['negative']:\n",
    "        result_neg3.append(word)\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Total positive words are {0}\".format(len(result_pos3)))\n",
    "print('Positive words are: ')\n",
    "print(result_pos3)\n",
    "print()\n",
    "print(\"Total negative words are {0}\".format(len(result_neg3)))\n",
    "print('Negative words are: ')\n",
    "print(result_neg3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Costco's total sentiment in 2015 was : 0.0021236432279377066\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Calculating\n",
    "(positive words - negative words)/total words\n",
    "'''\n",
    "\n",
    "pos3 = len(result_pos3)\n",
    "neg3 = len(result_neg3)\n",
    "\n",
    "sentiment3 = (pos3-neg3)/total_tokens3\n",
    "print()\n",
    "print(\"Costco's total sentiment in 2015 was : {0}\".format(sentiment3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see Costco's sentiment is neither increasing nor decreasing and thus we can't say\n",
    "whether the performance is improving or not."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
